import streamlit as st
import pandas as pd
import random
import requests
import re
from collections import Counter
from deep_translator import GoogleTranslator
import matplotlib
import matplotlib.pyplot as plt

# ğŸ› ï¸ å¼ºåˆ¶åå°ç”»å›¾ (é˜²ç™½å±)
matplotlib.use('Agg')

# --- 1. é¡µé¢é…ç½® ---
st.set_page_config(page_title="Ozon é€‰å“é›·è¾¾ (RapidAPIç‰ˆ)", page_icon="âš¡", layout="wide")
st.markdown("""
    <style>
    #MainMenu {visibility: hidden;}
    footer {visibility: hidden;}
    header {visibility: hidden;}
    .stMetric {background-color: #f0f2f6; padding: 15px; border-radius: 10px; text-align: center;}
    </style>
    """, unsafe_allow_html=True)

# --- 2. æ ¸å¿ƒåŠŸèƒ½ç±» ---
class OzonAnalyzer:
    def __init__(self):
        self.translator = GoogleTranslator(source='auto', target='zh-CN')

    def translate(self, text):
        try:
            return self.translator.translate(text)
        except:
            return text

    # ğŸ”¥ æ ¸å¿ƒä¿®æ”¹ï¼šé€‚é… RapidAPI (JSON æ¨¡å¼)
    def get_real_data(self, keyword):
        # 1. æ£€æŸ¥ Key
        api_key = st.secrets.get("RAPIDAPI_KEY", "")
        if not api_key or "YOUR" in api_key: return None 

        # 2. é…ç½® RapidAPI (è¿™é‡Œä½¿ç”¨é€šç”¨çš„ Ozon Scraper)
        url = "https://ozon-scraper-api.p.rapidapi.com/v1/search"
        
        headers = {
            "X-RapidAPI-Key": api_key,
            "X-RapidAPI-Host": "ozon-scraper-api.p.rapidapi.com"
        }
        
        params = {
            "text": keyword,
            "page": "1"
        }

        try:
            # å‘é€è¯·æ±‚ (JSON æ¥å£é€šå¸¸ 1-3 ç§’å°±è¿”å›)
            response = requests.get(url, headers=headers, params=params, timeout=15)
            
            if response.status_code != 200:
                # å¦‚æœæŠ¥é”™ï¼Œæ‰“å°ä¸€ä¸‹æ–¹ä¾¿è°ƒè¯•
                print(f"API Error: {response.status_code}")
                return None
            
            data = response.json()
            items = []
            
            # 3. è§£æ JSON (æ¯” HTML ç®€å•ä¸”ç²¾å‡†)
            # æ³¨æ„ï¼šä¸åŒçš„ RapidAPI æœåŠ¡å•†è¿”å›ç»“æ„ä¸åŒï¼Œè¿™æ˜¯æœ€å¸¸è§çš„ç»“æ„
            raw_items = data.get('items', [])
            
            for item in raw_items:
                try:
                    # ä»·æ ¼è§£æ (æœ‰äº›æ¥å£æ”¾åœ¨ price.amountï¼Œæœ‰äº›ç›´æ¥æ˜¯ price)
                    price = item.get('price', {}).get('amount', 0)
                    if price == 0: price = item.get('price_rub', 0) # å¤‡ç”¨å­—æ®µ
                    
                    # è¯„ä»·æ•°è§£æ
                    reviews = item.get('rating', {}).get('count', 0)
                    rating = float(item.get('rating', {}).get('average', 0.0))
                    
                    # æ ‡é¢˜
                    title = item.get('title', 'æœªçŸ¥å•†å“')
                    
                    items.append({
                        "title_origin": title,
                        "price_rub": float(price),
                        "reviews": int(reviews),
                        "rating": rating,
                        "link": item.get('url', f"https://www.ozon.ru/search/?text={keyword}"),
                        "is_real": True
                    })
                except:
                    continue
                    
            return items
        except Exception as e:
            print(f"Parsing Error: {e}")
            return None

    def get_mock_data(self, keyword):
        data = []
        base = random.randint(500, 3000)
        for i in range(20):
            price = max(100, base + random.randint(-500, 1500))
            data.append({
                "title_origin": f"[æ¨¡æ‹Ÿ] {keyword} æ ·å¼{chr(65+i)} Pro Max",
                "price_rub": price,
                "reviews": random.randint(10, 2000),
                "rating": round(random.uniform(3.0, 5.0), 1),
                "link": "https://www.ozon.ru",
                "is_real": False
            })
        return data

# --- 3. è¾…åŠ©åˆ†æå‡½æ•° ---
def extract_keywords(titles):
    text = " ".join(titles).lower()
    text = re.sub(r'[^\w\s]', '', text)
    words = text.split()
    stop_words = {'the', 'for', 'and', 'with', 'ozon', 'æ¨¡æ‹Ÿ', 'pro', 'set', 'new', 'cm', 'pcs'}
    filtered = [w for w in words if w not in stop_words and len(w) > 2]
    return Counter(filtered).most_common(10)

# --- 4. ç•Œé¢é€»è¾‘ ---
st.title("âš¡ Ozon é€‰å“é›·è¾¾ (RapidAPI æé€Ÿç‰ˆ)")
st.caption("æ•°æ®æº: RapidAPI (JSON) | çŠ¶æ€: ğŸš€ é«˜é€Ÿè¿æ¥ä¸­")

# ä¾§è¾¹æ 
with st.sidebar:
    st.header("âš™ï¸ å‚æ•°é…ç½®")
    keyword = st.text_input("ğŸ” æœç´¢å…³é”®è¯", "crochet bag")
    st.markdown("---")
    st.header("ğŸ’° åˆ©æ¶¦æ¨¡å‹")
    ex_rate = st.number_input("æ±‡ç‡ (CNY/RUB)", 0.075, format="%.4f")
    cost_cny = st.number_input("é‡‡è´­æˆæœ¬ (Â¥)", 40.0)
    fee = st.slider("å¹³å°ä½£é‡‘ (%)", 10, 40, 15) / 100

if st.button("ğŸš€ æé€ŸæŒ–æ˜", type="primary", use_container_width=True):
    
    analyzer = OzonAnalyzer()
    
    with st.spinner("âš¡ æ­£åœ¨é€šè¿‡ API è·å–ç²¾å‡†æ•°æ®..."):
        # 1. è·å–æ•°æ®
        raw = analyzer.get_real_data(keyword)
        if not raw:
            raw = analyzer.get_mock_data(keyword)
            is_mock = True
            st.toast("âš ï¸ API è¿æ¥æœªæˆåŠŸï¼Œå·²åˆ‡æ¢æ¼”ç¤ºæ•°æ®", icon="ğŸ’»")
        else:
            is_mock = False
            st.toast("âœ… æˆåŠŸè·å–çœŸå®æ•°æ®ï¼", icon="ğŸ‰")
            
        df = pd.DataFrame(raw)

        # 2. è®¡ç®—
        df['ä»·æ ¼ (Â¥)'] = df['price_rub'] * ex_rate
        df['å‡€åˆ©æ¶¦ (Â¥)'] = df['ä»·æ ¼ (Â¥)'] * (1 - fee) - cost_cny
        df['ROI (%)'] = (df['å‡€åˆ©æ¶¦ (Â¥)'] / cost_cny) * 100
        
        # 3. è¯„åˆ†
        df['çˆ†æ¬¾åˆ†'] = 0
        df.loc[df['ROI (%)'] > 30, 'çˆ†æ¬¾åˆ†'] += 40
        df.loc[df['reviews'] > 100, 'çˆ†æ¬¾åˆ†'] += 30
        
        # 4. ç¿»è¯‘
        df['ä¸­æ–‡æ ‡é¢˜'] = df['title_origin'].apply(analyzer.translate)
        df = df.sort_values("çˆ†æ¬¾åˆ†", ascending=False)

    # === ä»ªè¡¨æ¿ ===
    st.divider()
    m1, m2, m3, m4 = st.columns(4)
    if not df.empty:
        m1.metric("å¹³å‡å”®ä»·", f"â‚½{int(df['price_rub'].mean())}")
        m2.metric("å¹³å‡ ROI", f"{int(df['ROI (%)'].mean())}%")
        m3.metric("æœ€é«˜åˆ©æ¶¦", f"Â¥{int(df['å‡€åˆ©æ¶¦ (Â¥)'].max())}")
        m4.metric("æ•°æ®æ¥æº", "RapidAPI" if not is_mock else "æ¨¡æ‹Ÿæ¼”ç¤º")

    # === åŠŸèƒ½ Tabs ===
    tab1, tab2, tab3 = st.tabs(["ğŸ“‹ é€‰å“çŸ©é˜µ", "ğŸ“Š å¸‚åœºå›¾è¡¨", "ğŸ§  SEO åˆ†æ"])

    with tab1:
        st.subheader("å…¨é‡å•†å“æ•°æ®")
        st.dataframe(
            df.style.background_gradient(subset=['å‡€åˆ©æ¶¦ (Â¥)', 'ROI (%)'], cmap="RdYlGn"),
            column_config={
                "ä¸­æ–‡æ ‡é¢˜": st.column_config.TextColumn("å•†å“åç§°", width="medium"),
                "price_rub": st.column_config.NumberColumn("å¢å¸ƒä»·", format="â‚½%d"),
                "å‡€åˆ©æ¶¦ (Â¥)": st.column_config.NumberColumn("å‡€åˆ©", format="Â¥%.1f"),
                "ROI (%)": st.column_config.NumberColumn("ROI", format="%.0f%%"),
                "link": st.column_config.LinkColumn("é“¾æ¥"),
            },
            use_container_width=True
        )
        # ä¸‹è½½æŒ‰é’®
        csv = df.to_csv(index=False).encode('utf-8-sig')
        st.download_button("ğŸ“¥ å¯¼å‡º Excel", data=csv, file_name=f'ozon_{keyword}.csv', mime='text/csv')

    with tab2:
        c1, c2 = st.columns(2)
        with c1:
            st.markdown("**ğŸ’° ä»·æ ¼åˆ†å¸ƒ**")
            st.bar_chart(df['price_rub'].value_counts(bins=5).sort_index())
        with c2:
            st.markdown("**ğŸ’ è“æµ·å¯»æ‰¾ (ä»·æ ¼ vs è¯„ä»·)**")
            st.scatter_chart(df, x='price_rub', y='reviews', color='ROI (%)')

    with tab3:
        st.markdown("**ğŸ”‘ çˆ†æ¬¾æ ‡é¢˜çƒ­è¯**")
        kw_df = pd.DataFrame(extract_keywords(df['title_origin'].tolist()), columns=['è¯', 'é¢‘æ¬¡'])
        st.bar_chart(kw_df.set_index('è¯'))
